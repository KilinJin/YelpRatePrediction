{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This script aggregates all the reviews for restaurants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from rake_nltk import Rake\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59371\n"
     ]
    }
   ],
   "source": [
    "restaurants = []\n",
    "with open ('/Users/jiamingqu/Desktop/yelp_dataset/restaurant.txt', 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        restaurants.append(line.strip())\n",
    "\n",
    "print(len(restaurants))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n",
      "100000\n",
      "150000\n",
      "200000\n",
      "250000\n",
      "300000\n",
      "350000\n",
      "400000\n",
      "450000\n",
      "500000\n",
      "550000\n",
      "600000\n",
      "650000\n",
      "700000\n",
      "750000\n",
      "800000\n",
      "850000\n",
      "900000\n",
      "950000\n",
      "1000000\n",
      "1050000\n",
      "1100000\n",
      "1150000\n",
      "1200000\n",
      "1250000\n",
      "1300000\n",
      "1350000\n",
      "1400000\n",
      "1450000\n",
      "1500000\n",
      "1550000\n",
      "1600000\n",
      "1650000\n",
      "1700000\n",
      "1750000\n",
      "1800000\n",
      "1850000\n",
      "1900000\n",
      "1950000\n",
      "2000000\n",
      "2050000\n",
      "2100000\n",
      "2150000\n",
      "2200000\n",
      "2250000\n",
      "2300000\n",
      "2350000\n",
      "2400000\n",
      "2450000\n",
      "2500000\n",
      "2550000\n",
      "2600000\n",
      "2650000\n",
      "2700000\n",
      "2750000\n",
      "2800000\n",
      "2850000\n",
      "2900000\n",
      "2950000\n",
      "3000000\n",
      "3050000\n",
      "3100000\n",
      "3150000\n",
      "3200000\n",
      "3250000\n",
      "3300000\n",
      "3350000\n",
      "3400000\n",
      "3450000\n",
      "3500000\n",
      "3550000\n",
      "3600000\n",
      "3650000\n",
      "3700000\n",
      "3750000\n",
      "3800000\n",
      "3850000\n",
      "3900000\n",
      "3950000\n",
      "4000000\n",
      "4050000\n",
      "4100000\n",
      "4150000\n",
      "4200000\n"
     ]
    }
   ],
   "source": [
    "restaurants_reviews = {}\n",
    "count = 0\n",
    "\n",
    "with open ('/Users/jiamingqu/Desktop/yelp_dataset/review.json', 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        review = json.loads(line)\n",
    "        business_id = review[\"business_id\"]\n",
    "        if business_id in restaurants:\n",
    "            restaurants_reviews.setdefault(business_id, []).append(review)\n",
    "        else:\n",
    "            continue\n",
    "            \n",
    "        count += 1\n",
    "        if count % 50000 == 0:\n",
    "            print(count)\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# average amount of reviews\n",
    "review_count = np.array([])\n",
    "for k,v in restaurants_reviews.items():\n",
    "    review_count = np.append(review_count, len(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70.76997187178925"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(review_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use RAKE to extract keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# first aggregate reviews\n",
    "restaurants_all_reviews = {}\n",
    "review_word_count = np.array([])\n",
    "count = 0\n",
    "\n",
    "for k,v in restaurants_reviews.items():\n",
    "    \n",
    "    all_reviews_list = []\n",
    "    for i in v:\n",
    "        all_reviews_list.append(i[\"text\"])\n",
    "    all_reviews = \" \".join(all_reviews_list)\n",
    "    \n",
    "    review_words = len(all_reviews.split(\" \"))\n",
    "    review_word_count = np.append(review_word_count, review_words)\n",
    "    \n",
    "    restaurants_all_reviews[k] = all_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7710.874972629735"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# average count of words in reviews\n",
    "np.mean(review_word_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "\n",
    "    '''\n",
    "    Args: a list of documents\n",
    "    Returns: a list of cleaned text\n",
    "    '''\n",
    "\n",
    "    # clean and tokenize document string\n",
    "    raw_text = text.lower()\n",
    "    raw_text = re.sub(r\"[^\\w\\s]\", \"\", raw_text)\n",
    "    tokens = nltk.word_tokenize(raw_text)\n",
    "\n",
    "    # remove stop words from tokens\n",
    "    stop = stopwords.words(\"english\")\n",
    "    cleaned_tokens = [token for token in tokens if token not in stop]\n",
    "\n",
    "    return \" \".join(cleaned_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurant_all_reviews_keywords = {}\n",
    "\n",
    "for k, v in restaurants_all_reviews.items():\n",
    "    \n",
    "    r = Rake()\n",
    "    r.extract_keywords_from_text(v)\n",
    "    ranked_list = r.get_ranked_phrases()\n",
    "    \n",
    "    keywords = \" \".join(ranked_list[:100])\n",
    "    \n",
    "    restaurant_all_reviews_keywords[k] = clean_text(keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "317.67438648498427"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keyword_count = np.array([])\n",
    "\n",
    "for v in restaurant_all_reviews_keywords.values():\n",
    "    keyword_count = np.append(keyword_count, len(v.split(\" \")))\n",
    "\n",
    "# average count of words in keywords\n",
    "np.mean(keyword_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check\n",
    "assert len(restaurant_all_reviews_keywords.items()) == len(restaurants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open (\"/Users/jiamingqu/Desktop/yelp_dataset/restaurant.reviews/restaurant.keywords.json\", 'w') as f:\n",
    "    json.dump(restaurant_all_reviews_keywords, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
