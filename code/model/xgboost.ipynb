{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1237673, 20)\n",
      "(1237673,)\n"
     ]
    }
   ],
   "source": [
    "# read data\n",
    "training_x = list()\n",
    "with open (\"../training_X_with_text_features.json\",'r') as data:\n",
    "    for d in data:\n",
    "        training_x = json.loads(d)\n",
    "        \n",
    "# read data\n",
    "training_y = list()\n",
    "with open (\"../training_Y_with_text_features.json\",'r') as data:\n",
    "    for d in data:\n",
    "        training_y = json.loads(d)\n",
    "        \n",
    "training_x = np.array(training_x)\n",
    "training_y = np.array(training_y)\n",
    "\n",
    "print(training_x.shape)\n",
    "print(training_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select 20% of the data to do CV to tune parameters\n",
    "part_training_x = training_x[:round(0.2*(training_x.shape[0])),:]\n",
    "part_training_y = training_y[:round(0.2*(training_x.shape[0]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we do not do feature selection for xgboost\n",
    "# because xgboost itself will find important/unimportant features\n",
    "# we set threshold as a parameter to select features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use grid search to tune the hyperparameters\n",
    "# hyper parameters list\n",
    "\n",
    "max_depth_list = [2,4,6,8,10]\n",
    "n_estimators_list = [*range(100, 600, 100)]\n",
    "learning_rate_list = [0.05, 0.01]\n",
    "colsample_bytree_list = [0.6,0.8,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.159 2,100,0.05,0.6\n",
      "1.159 2,100,0.05,0.8\n",
      "1.159 2,100,0.05,1\n",
      "1.188 2,100,0.01,0.6\n",
      "1.188 2,100,0.01,0.8\n",
      "1.188 2,100,0.01,1\n",
      "1.159 2,200,0.05,0.6\n",
      "1.159 2,200,0.05,0.8\n",
      "1.159 2,200,0.05,1\n",
      "1.173 2,200,0.01,0.6\n",
      "1.173 2,200,0.01,0.8\n",
      "1.173 2,200,0.01,1\n",
      "1.163 2,300,0.05,0.6\n",
      "1.163 2,300,0.05,0.8\n",
      "1.163 2,300,0.05,1\n",
      "1.166 2,300,0.01,0.6\n",
      "1.166 2,300,0.01,0.8\n",
      "1.166 2,300,0.01,1\n",
      "1.169 2,400,0.05,0.6\n",
      "1.169 2,400,0.05,0.8\n",
      "1.169 2,400,0.05,1\n",
      "1.163 2,400,0.01,0.6\n",
      "1.163 2,400,0.01,0.8\n",
      "1.163 2,400,0.01,1\n",
      "1.177 2,500,0.05,0.6\n",
      "1.177 2,500,0.05,0.8\n",
      "1.177 2,500,0.05,1\n",
      "1.161 2,500,0.01,0.6\n",
      "1.161 2,500,0.01,0.8\n",
      "1.161 2,500,0.01,1\n",
      "1.159 4,100,0.05,0.6\n",
      "1.159 4,100,0.05,0.8\n",
      "1.159 4,100,0.05,1\n",
      "1.188 4,100,0.01,0.6\n",
      "1.188 4,100,0.01,0.8\n",
      "1.188 4,100,0.01,1\n",
      "1.159 4,200,0.05,0.6\n",
      "1.159 4,200,0.05,0.8\n",
      "1.159 4,200,0.05,1\n",
      "1.173 4,200,0.01,0.6\n",
      "1.173 4,200,0.01,0.8\n",
      "1.173 4,200,0.01,1\n",
      "1.163 4,300,0.05,0.6\n",
      "1.163 4,300,0.05,0.8\n",
      "1.163 4,300,0.05,1\n",
      "1.166 4,300,0.01,0.6\n",
      "1.166 4,300,0.01,0.8\n",
      "1.166 4,300,0.01,1\n",
      "1.169 4,400,0.05,0.6\n",
      "1.169 4,400,0.05,0.8\n",
      "1.169 4,400,0.05,1\n",
      "1.163 4,400,0.01,0.6\n",
      "1.163 4,400,0.01,0.8\n",
      "1.163 4,400,0.01,1\n",
      "1.177 4,500,0.05,0.6\n",
      "1.177 4,500,0.05,0.8\n",
      "1.177 4,500,0.05,1\n",
      "1.161 4,500,0.01,0.6\n",
      "1.161 4,500,0.01,0.8\n",
      "1.161 4,500,0.01,1\n",
      "1.159 6,100,0.05,0.6\n",
      "1.159 6,100,0.05,0.8\n",
      "1.159 6,100,0.05,1\n",
      "1.188 6,100,0.01,0.6\n",
      "1.188 6,100,0.01,0.8\n",
      "1.188 6,100,0.01,1\n",
      "1.159 6,200,0.05,0.6\n",
      "1.159 6,200,0.05,0.8\n",
      "1.159 6,200,0.05,1\n",
      "1.173 6,200,0.01,0.6\n",
      "1.173 6,200,0.01,0.8\n",
      "1.173 6,200,0.01,1\n",
      "1.163 6,300,0.05,0.6\n",
      "1.163 6,300,0.05,0.8\n",
      "1.163 6,300,0.05,1\n",
      "1.166 6,300,0.01,0.6\n",
      "1.166 6,300,0.01,0.8\n",
      "1.166 6,300,0.01,1\n",
      "1.169 6,400,0.05,0.6\n",
      "1.169 6,400,0.05,0.8\n",
      "1.169 6,400,0.05,1\n",
      "1.163 6,400,0.01,0.6\n",
      "1.163 6,400,0.01,0.8\n",
      "1.163 6,400,0.01,1\n",
      "1.177 6,500,0.05,0.6\n",
      "1.177 6,500,0.05,0.8\n",
      "1.177 6,500,0.05,1\n",
      "1.161 6,500,0.01,0.6\n",
      "1.161 6,500,0.01,0.8\n",
      "1.161 6,500,0.01,1\n",
      "1.159 8,100,0.05,0.6\n",
      "1.159 8,100,0.05,0.8\n",
      "1.159 8,100,0.05,1\n",
      "1.188 8,100,0.01,0.6\n",
      "1.188 8,100,0.01,0.8\n",
      "1.188 8,100,0.01,1\n",
      "1.159 8,200,0.05,0.6\n",
      "1.159 8,200,0.05,0.8\n",
      "1.159 8,200,0.05,1\n",
      "1.173 8,200,0.01,0.6\n",
      "1.173 8,200,0.01,0.8\n",
      "1.173 8,200,0.01,1\n",
      "1.163 8,300,0.05,0.6\n",
      "1.163 8,300,0.05,0.8\n",
      "1.163 8,300,0.05,1\n",
      "1.166 8,300,0.01,0.6\n",
      "1.166 8,300,0.01,0.8\n",
      "1.166 8,300,0.01,1\n",
      "1.169 8,400,0.05,0.6\n",
      "1.169 8,400,0.05,0.8\n",
      "1.169 8,400,0.05,1\n",
      "1.163 8,400,0.01,0.6\n",
      "1.163 8,400,0.01,0.8\n",
      "1.163 8,400,0.01,1\n",
      "1.177 8,500,0.05,0.6\n",
      "1.177 8,500,0.05,0.8\n",
      "1.177 8,500,0.05,1\n",
      "1.161 8,500,0.01,0.6\n",
      "1.161 8,500,0.01,0.8\n",
      "1.161 8,500,0.01,1\n",
      "1.159 10,100,0.05,0.6\n",
      "1.159 10,100,0.05,0.8\n",
      "1.159 10,100,0.05,1\n",
      "1.188 10,100,0.01,0.6\n",
      "1.188 10,100,0.01,0.8\n",
      "1.188 10,100,0.01,1\n",
      "1.159 10,200,0.05,0.6\n",
      "1.159 10,200,0.05,0.8\n",
      "1.159 10,200,0.05,1\n",
      "1.173 10,200,0.01,0.6\n",
      "1.173 10,200,0.01,0.8\n",
      "1.173 10,200,0.01,1\n",
      "1.163 10,300,0.05,0.6\n",
      "1.163 10,300,0.05,0.8\n",
      "1.163 10,300,0.05,1\n",
      "1.166 10,300,0.01,0.6\n",
      "1.166 10,300,0.01,0.8\n",
      "1.166 10,300,0.01,1\n",
      "1.169 10,400,0.05,0.6\n",
      "1.169 10,400,0.05,0.8\n",
      "1.169 10,400,0.05,1\n",
      "1.163 10,400,0.01,0.6\n",
      "1.163 10,400,0.01,0.8\n",
      "1.163 10,400,0.01,1\n",
      "1.177 10,500,0.05,0.6\n",
      "1.177 10,500,0.05,0.8\n",
      "1.177 10,500,0.05,1\n",
      "1.161 10,500,0.01,0.6\n",
      "1.161 10,500,0.01,0.8\n",
      "1.161 10,500,0.01,1\n"
     ]
    }
   ],
   "source": [
    "results_dict = dict()\n",
    "for a in max_depth_list:\n",
    "    for b in n_estimators_list:\n",
    "        for c in learning_rate_list:\n",
    "            for d in colsample_bytree_list:\n",
    "                \n",
    "                xgboost = XGBRegressor(objective='reg:squarederror', n_jobs=-1, \n",
    "                                       reg_alpha = 0.5, reg_lambda=0.5, radom_state=2020,\n",
    "                                       max_depth=a, n_estimators=b, learning_rate=c, colsample_bytree=d)\n",
    "\n",
    "                cv_results = cross_validate(xgboost, part_training_x, part_training_y, cv=3, scoring=('neg_mean_squared_error'))\n",
    "                results = -cv_results['test_score']\n",
    "                key = \"{},{},{},{}\".format(a,b,c,d)\n",
    "                results_dict[key] = round(np.mean(results),5)\n",
    "                print(round(np.mean(results),3), \"{},{},{},{}\".format(a,b,c,d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_results = sorted(results_dict.items(),key = lambda x:x[0], reverse = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1.1587, '10,200,0.05,1'),\n",
       " (1.15901, '10,100,0.05,1'),\n",
       " (1.16089, '10,500,0.01,1'),\n",
       " (1.16271, '10,400,0.01,1'),\n",
       " (1.16318, '10,300,0.05,1'),\n",
       " (1.16607, '10,300,0.01,1'),\n",
       " (1.16939, '10,400,0.05,1'),\n",
       " (1.17293, '10,200,0.01,1'),\n",
       " (1.17687, '10,500,0.05,1'),\n",
       " (1.18777, '10,100,0.01,1')]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_results[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it shows that max_depth should be = 10, colsample_bytree_list should be = 1\n",
    "# learning rate seems does not matter\n",
    "# tree number = 200 is locally optimial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-tune\n",
    "max_depth_list = [8,10,12,14,20] # add 20 to see whether the deeper the tree is, the better the result is\n",
    "n_estimators_list = [150,200,250,300,350,400]\n",
    "learning_rate_list = [0.01,0.05] # 0.05 and 0.01 do not differ too much\n",
    "colsample_bytree_list = [1] # should be 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.179 8,150,0.01,1\n",
      "1.158 8,150,0.05,1\n",
      "1.173 8,200,0.01,1\n",
      "1.159 8,200,0.05,1\n",
      "1.169 8,250,0.01,1\n",
      "1.161 8,250,0.05,1\n",
      "1.166 8,300,0.01,1\n",
      "1.163 8,300,0.05,1\n",
      "1.164 8,350,0.01,1\n",
      "1.166 8,350,0.05,1\n",
      "1.163 8,400,0.01,1\n",
      "1.169 8,400,0.05,1\n",
      "1.179 10,150,0.01,1\n",
      "1.158 10,150,0.05,1\n",
      "1.173 10,200,0.01,1\n",
      "1.159 10,200,0.05,1\n",
      "1.169 10,250,0.01,1\n",
      "1.161 10,250,0.05,1\n",
      "1.166 10,300,0.01,1\n",
      "1.163 10,300,0.05,1\n",
      "1.164 10,350,0.01,1\n",
      "1.166 10,350,0.05,1\n",
      "1.163 10,400,0.01,1\n",
      "1.169 10,400,0.05,1\n",
      "1.179 12,150,0.01,1\n",
      "1.158 12,150,0.05,1\n",
      "1.173 12,200,0.01,1\n",
      "1.159 12,200,0.05,1\n",
      "1.169 12,250,0.01,1\n",
      "1.161 12,250,0.05,1\n",
      "1.166 12,300,0.01,1\n",
      "1.163 12,300,0.05,1\n",
      "1.164 12,350,0.01,1\n",
      "1.166 12,350,0.05,1\n",
      "1.163 12,400,0.01,1\n",
      "1.169 12,400,0.05,1\n",
      "1.179 14,150,0.01,1\n",
      "1.158 14,150,0.05,1\n",
      "1.173 14,200,0.01,1\n",
      "1.159 14,200,0.05,1\n",
      "1.169 14,250,0.01,1\n",
      "1.161 14,250,0.05,1\n",
      "1.166 14,300,0.01,1\n",
      "1.163 14,300,0.05,1\n",
      "1.164 14,350,0.01,1\n",
      "1.166 14,350,0.05,1\n",
      "1.163 14,400,0.01,1\n",
      "1.169 14,400,0.05,1\n",
      "1.179 20,150,0.01,1\n",
      "1.158 20,150,0.05,1\n",
      "1.173 20,200,0.01,1\n",
      "1.159 20,200,0.05,1\n",
      "1.169 20,250,0.01,1\n",
      "1.161 20,250,0.05,1\n",
      "1.166 20,300,0.01,1\n",
      "1.163 20,300,0.05,1\n",
      "1.164 20,350,0.01,1\n",
      "1.166 20,350,0.05,1\n",
      "1.163 20,400,0.01,1\n",
      "1.169 20,400,0.05,1\n"
     ]
    }
   ],
   "source": [
    "results_dict = dict()\n",
    "for a in max_depth_list:\n",
    "    for b in n_estimators_list:\n",
    "        for c in learning_rate_list:\n",
    "            for d in colsample_bytree_list:\n",
    "                \n",
    "                xgboost = XGBRegressor(objective='reg:squarederror', n_jobs=-1, \n",
    "                                       reg_alpha = 0.5, reg_lambda=0.5, radom_state=2020,\n",
    "                                       max_depth=a, n_estimators=b, learning_rate=c, colsample_bytree=d)\n",
    "\n",
    "                cv_results = cross_validate(xgboost, part_training_x, part_training_y, cv=3, scoring=('neg_mean_squared_error'))\n",
    "                results = -cv_results['test_score']\n",
    "                key = \"{},{},{},{}\".format(a,b,c,d)\n",
    "                results_dict[key] = round(np.mean(results),5)\n",
    "                print(round(np.mean(results),3), \"{},{},{},{}\".format(a,b,c,d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('8,150,0.05,1', 1.15795),\n",
       " ('10,150,0.05,1', 1.15795),\n",
       " ('12,150,0.05,1', 1.15795),\n",
       " ('14,150,0.05,1', 1.15795),\n",
       " ('20,150,0.05,1', 1.15795)]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_results = sorted(results_dict.items(),key = lambda x:x[1], reverse = False)\n",
    "sorted_results[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(280588, 20)\n",
      "(280588,)\n"
     ]
    }
   ],
   "source": [
    "# read testing data\n",
    "testing_x = list()\n",
    "with open (\"../testing_X_with_text_features.json\",'r') as data:\n",
    "    for d in data:\n",
    "        testing_x = json.loads(d)\n",
    "        \n",
    "# read data\n",
    "testing_y = list()\n",
    "with open (\"../testing_Y_with_text_features.json\",'r') as data:\n",
    "    for d in data:\n",
    "        testing_y = json.loads(d)\n",
    "        \n",
    "testing_x = np.array(testing_x)\n",
    "testing_y = np.array(testing_y)\n",
    "\n",
    "print(testing_x.shape)\n",
    "print(testing_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "             importance_type='gain', interaction_constraints=None,\n",
       "             learning_rate=0.05, max_delta_step=0, max_depth=8,\n",
       "             min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=150, n_jobs=-1, num_parallel_tree=1,\n",
       "             objective='reg:squarederror', radom_state=2020, random_state=0,\n",
       "             reg_alpha=0.5, reg_lambda=0.5, scale_pos_weight=1, subsample=1,\n",
       "             tree_method=None, validate_parameters=False, verbosity=None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgboost = XGBRegressor(objective='reg:squarederror', n_jobs=-1, \n",
    "                       reg_alpha = 0.5, reg_lambda=0.5, radom_state=2020,\n",
    "                       max_depth=8, n_estimators=150, learning_rate=0.05, colsample_bytree=1)\n",
    "xgboost.fit(training_x,training_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.9623332, 3.4999278, 3.7187412, ..., 1.7249293, 3.294361 ,\n",
       "       3.7275891], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_ratings = xgboost.predict(testing_x)\n",
    "predicted_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = sqrt(mean_squared_error(predicted_ratings, testing_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3052879027153284"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = dict()\n",
    "for i in range(20):\n",
    "    feature_importances[i] = xgboost.feature_importances_[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(5, 0.43537405),\n",
       " (1, 0.3339936),\n",
       " (7, 0.03962766),\n",
       " (14, 0.026047422),\n",
       " (0, 0.019585058),\n",
       " (9, 0.019291928),\n",
       " (19, 0.01710789),\n",
       " (2, 0.013922511),\n",
       " (6, 0.013712737),\n",
       " (11, 0.013301014),\n",
       " (16, 0.012709208),\n",
       " (17, 0.012649105),\n",
       " (12, 0.012256892),\n",
       " (4, 0.010883451),\n",
       " (10, 0.010047506),\n",
       " (15, 0.009489982),\n",
       " (3, 0.0),\n",
       " (8, 0.0),\n",
       " (13, 0.0),\n",
       " (18, 0.0)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(feature_importances.items(), key=lambda x:x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature No. 5, 1, 7, 14, 0 are more important\n",
    "# this can be compared with important features in other models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
